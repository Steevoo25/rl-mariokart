% !TEX root =  ../Dissertation.tex
% how to cite github projects?
\chapter{Literature Review}
\section{Existing Work}
Due to its popularity, it is no surprise that very similar projects have been conducted. Jack Boynton gave a presentation on Deep-Reinforcement Learning \cite{JackWBoynton} where his agent used checkpoints throughout the map as inputs for the reward function and a series of positions and vectors along with pixel data to represent the state. An implementation of Hindsight Experience Replay Buffer (HER) \cite{andrychowicz2017hindsight} , which was used to deal with the sparsity of rewards. An interesting component of the state space is Cross-Track Error, which measures how far off the kart is from a pre-defined desired path. \\Ben Middleton's AI Environment \cite{BenJMiddleton} implemented an adapted version of the Rainbow Agent \cite{RainbowAgent} \cite{hessel2018rainbow} to run with Dolphin. This implementation used data from RAM, such as race completion and speed, as well as pixel data to train, and resulted in great performance in terms of lap time. This is the implementation I will be comparing mine with due to its similarities in state space, but differences in implementation, allowing insightful data analysis. 
\section{RL in Games}
Games, being a popular hobby, have naturally stood out as an enticing environment to showcase advancements in Reinforcement Learning. They suit the paradigm well, due to the huge range of games available, ...
\cite{mnih2013playing}Playing atari with rl - used as benchmark for deep-rl, over X references, compares deep and traditional in 2-d games (DQN, sarsa)\\FPS games with deep-rl - compares a trained agent with human players in deathmatch scenario - implements visual data alongside q-learning objective\cite{lample2017playing}\\End-To-End race driving - deep-rl in realistic racing game\cite{8460934} -
\section{Real-World Applications}
many papers published for autonomous driving (more than 1,000,000) 
\\Hierarchical rl - suggests manouvre selection policy and motion control - allowing for tuning of same manouevre for slightly different situations\cite{duan2020hierarchical}
\\Deep rl for autonomous driving \cite{kiran2021deep} lots of appliations for rl within autonomous driving - control, recognition, Planning, Behaviour prediction (other drivers)