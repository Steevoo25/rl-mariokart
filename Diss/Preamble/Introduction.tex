\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
A self-driving car was once a concept of the future, but driving models continue to become a reality thanks to breakthroughs in Artificial Intelligence such as Convolutional Neural Networks (CNNs), successfully completing End-to-End driving, including lane and road following, in a range of locations and conditions.\cite{DBLP:journals/corr/BojarskiTDFFGJM16}. However, these complex developments come at a cost. Image processing in particular is heavily GPU reliant and therefore not always accessible, in particular to those without this hardware. My project focuses on the effectiveness and relevance of 'traditional' RL approaches compared to D-RL when applied to the same scenario.\\
Deep Q Networks (DQN) have been shown to achieve a performance level comparable to that of a professional human games tester \cite{mnih2015human}, but is this level also achievable with 'traditional' RL approaches such as SARSA \cite{rummery1994line} or Q-Learning \cite{watkins1992q}? For my experiments, I chose to I compare Q-Learning (RL) and Rainbow (D-RL) \cite{hessel2018rainbow}, where Rainbow is a combination of various extensions to (DQN), greatly improving its performance. \\
The scenario I have chosen for this is Mariokart Wii. Its huge popularity \textit{(Over 38 million copies sold)} means that this is a familiar environment for many, unlocking the potential for use in education. This, paired with my great interest and passion for the game, made it a clear choice for my project. In order to do this I required some Emulation software. Dolphin Emulator \cite{DolphinEmulator} is a free, open source Wii emulator with a plethora of useful features. My past experience with Dolphin, along with its wide use within the community made Dolphin the obvious candidate for my use case.